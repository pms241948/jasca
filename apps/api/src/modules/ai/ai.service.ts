import { Injectable, Logger } from '@nestjs/common';
import { PrismaService } from '../../prisma/prisma.service';
import { AiActionType, AI_PROMPTS, AI_ACTION_METADATA } from './ai-actions';

export interface RiskSummary {
    projectId: string;
    projectName: string;
    summary: string;
    riskLevel: 'CRITICAL' | 'HIGH' | 'MEDIUM' | 'LOW';
    keyFindings: string[];
    recommendations: string[];
    generatedAt: Date;
}

export interface RemediationGuide {
    cveId: string;
    title: string;
    severity: string;
    description: string;
    steps: string[];
    references: string[];
    estimatedEffort: 'LOW' | 'MEDIUM' | 'HIGH';
    generatedAt: Date;
}

export interface AiExecutionResult {
    id: string;
    action: AiActionType;
    content: string;
    summary?: string;
    model?: string;
    inputTokens?: number;
    outputTokens?: number;
    usedPrompt?: string;
}

export interface TokenEstimate {
    inputTokens: number;
    outputTokens: number;
}

@Injectable()
export class AiService {
    private readonly logger = new Logger(AiService.name);

    constructor(private readonly prisma: PrismaService) { }

    /**
     * Get AI settings from database
     */
    private async getAiSettings(): Promise<{
        provider: string;
        apiUrl: string;
        apiKey?: string;
        model: string;
        enabled: boolean;
    } | null> {
        try {
            const settings = await this.prisma.systemSettings.findUnique({
                where: { key: 'ai' },
            });
            if (!settings) return null;

            const value = settings.value as Record<string, unknown>;
            return {
                provider: (value.provider as string) || 'ollama',
                apiUrl: (value.apiUrl as string) || 'http://localhost:11434',
                apiKey: value.apiKey as string | undefined,
                // Use summaryModel or remediationModel field from settings
                model: (value.summaryModel as string) || (value.model as string) || 'llama3.2',
                enabled: (value.enableAutoSummary as boolean) ?? (value.enabled as boolean) ?? true,
            };
        } catch (error) {
            this.logger.warn('Failed to fetch AI settings:', error);
            return null;
        }
    }

    /**
     * Get prompt for action (custom from DB or default)
     */
    async getPromptForAction(action: AiActionType): Promise<string> {
        try {
            const customPrompts = await this.prisma.systemSettings.findUnique({
                where: { key: 'ai_prompts' },
            });

            if (customPrompts) {
                const prompts = customPrompts.value as Record<string, string>;
                if (prompts[action]) {
                    return prompts[action];
                }
            }
        } catch (error) {
            this.logger.warn('Failed to fetch custom prompts:', error);
        }

        // Return default prompt
        return AI_PROMPTS[action] || '';
    }

    /**
     * Get all prompts (custom + defaults)
     */
    async getAllPrompts(): Promise<Record<string, { prompt: string; isCustom: boolean; label: string; description: string }>> {
        let customPrompts: Record<string, string> = {};

        try {
            const settings = await this.prisma.systemSettings.findUnique({
                where: { key: 'ai_prompts' },
            });
            if (settings) {
                customPrompts = settings.value as Record<string, string>;
            }
        } catch (error) {
            this.logger.warn('Failed to fetch custom prompts:', error);
        }

        const result: Record<string, { prompt: string; isCustom: boolean; label: string; description: string }> = {};

        for (const action of Object.values(AiActionType)) {
            const metadata = AI_ACTION_METADATA[action];
            result[action] = {
                prompt: customPrompts[action] || AI_PROMPTS[action] || '',
                isCustom: !!customPrompts[action],
                label: metadata?.label || action,
                description: metadata?.description || '',
            };
        }

        return result;
    }

    /**
     * Update prompt for action
     */
    async updatePrompt(action: AiActionType, prompt: string): Promise<void> {
        let customPrompts: Record<string, string> = {};

        try {
            const settings = await this.prisma.systemSettings.findUnique({
                where: { key: 'ai_prompts' },
            });
            if (settings) {
                customPrompts = settings.value as Record<string, string>;
            }
        } catch (error) {
            // Continue with empty prompts
        }

        customPrompts[action] = prompt;

        await this.prisma.systemSettings.upsert({
            where: { key: 'ai_prompts' },
            update: { value: customPrompts as any },
            create: { key: 'ai_prompts', value: customPrompts as any },
        });
    }

    /**
     * Reset prompt to default
     */
    async resetPrompt(action: AiActionType): Promise<void> {
        try {
            const settings = await this.prisma.systemSettings.findUnique({
                where: { key: 'ai_prompts' },
            });

            if (settings) {
                const customPrompts = settings.value as Record<string, string>;
                delete customPrompts[action];

                await this.prisma.systemSettings.update({
                    where: { key: 'ai_prompts' },
                    data: { value: customPrompts as any },
                });
            }
        } catch (error) {
            this.logger.warn('Failed to reset prompt:', error);
        }
    }
    /**
     * Execute AI action with given context
     */
    async executeAction(
        action: AiActionType,
        context: Record<string, unknown>,
        userId: string,
    ): Promise<AiExecutionResult> {
        this.logger.log(`Executing AI action: ${action} for user: ${userId}`);

        // Get AI settings from database
        const aiSettings = await this.getAiSettings();

        // Get the prompt template (custom or default)
        const promptTemplate = await this.getPromptForAction(action);
        const metadata = AI_ACTION_METADATA[action];

        // Build the full prompt with context
        const maskedContext = this.maskPii(JSON.stringify(context, null, 2));
        const fullPrompt = `${promptTemplate}\n\n**ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°:**\n\`\`\`json\n${maskedContext}\n\`\`\``;

        let content: string;
        let modelName: string;

        // If AI settings exist and enabled, use real AI
        if (aiSettings?.enabled && aiSettings.apiUrl) {
            try {
                const result = await this.callAiProvider(aiSettings, fullPrompt);
                content = result.content;
                modelName = result.model;
                this.logger.log(`AI call successful using ${aiSettings.provider}/${modelName}`);
            } catch (error) {
                this.logger.error('AI call failed, falling back to mock:', error);
                content = await this.generateMockResponse(action, context);
                modelName = 'mock-model-v1 (fallback)';
            }
        } else {
            // Fallback to mock response
            this.logger.warn('AI settings not configured, using mock response');
            content = await this.generateMockResponse(action, context);
            modelName = 'mock-model-v1';
        }

        // Estimate tokens
        const estimate = this.estimateTokens(action, context);

        // Log the execution
        this.logger.log(`AI execution completed. Model: ${modelName}, Input tokens: ${estimate.inputTokens}, Output tokens: ${estimate.outputTokens}`);

        return {
            id: crypto.randomUUID(),
            action,
            content,
            summary: this.generateSummaryFromContent(content),
            model: modelName,
            inputTokens: estimate.inputTokens,
            outputTokens: estimate.outputTokens,
            usedPrompt: promptTemplate,
        };
    }

    /**
     * Call AI provider (Ollama, vLLM, OpenAI, etc.)
     */
    private async callAiProvider(
        settings: { provider: string; apiUrl: string; apiKey?: string; model: string },
        prompt: string,
    ): Promise<{ content: string; model: string }> {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 60000); // 60s timeout

        try {
            switch (settings.provider) {
                case 'ollama':
                    return await this.callOllama(settings.apiUrl, settings.model, prompt, controller.signal);
                case 'vllm':
                    return await this.callVllm(settings.apiUrl, settings.model, prompt, settings.apiKey, controller.signal);
                case 'openai':
                    return await this.callOpenAi(settings.apiUrl, settings.model, prompt, settings.apiKey!, controller.signal);
                default:
                    throw new Error(`Unsupported AI provider: ${settings.provider}`);
            }
        } finally {
            clearTimeout(timeoutId);
        }
    }

    /**
     * Call Ollama API
     */
    private async callOllama(
        apiUrl: string,
        model: string,
        prompt: string,
        signal: AbortSignal,
    ): Promise<{ content: string; model: string }> {
        const response = await fetch(`${apiUrl}/api/generate`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model,
                prompt,
                stream: false,
                options: {
                    temperature: 0.7,
                    top_p: 0.9,
                },
            }),
            signal,
        });

        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`Ollama API error: ${response.status} - ${errorText}`);
        }

        const data = await response.json() as { response: string; model: string };
        return {
            content: data.response,
            model: data.model || model,
        };
    }

    /**
     * Call vLLM API (OpenAI-compatible)
     */
    private async callVllm(
        apiUrl: string,
        model: string,
        prompt: string,
        apiKey: string | undefined,
        signal: AbortSignal,
    ): Promise<{ content: string; model: string }> {
        const headers: Record<string, string> = { 'Content-Type': 'application/json' };
        if (apiKey) headers['Authorization'] = `Bearer ${apiKey}`;

        const response = await fetch(`${apiUrl}/v1/completions`, {
            method: 'POST',
            headers,
            body: JSON.stringify({
                model,
                prompt,
                max_tokens: 2000,
                temperature: 0.7,
            }),
            signal,
        });

        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`vLLM API error: ${response.status} - ${errorText}`);
        }

        const data = await response.json() as { choices: Array<{ text: string }>; model: string };
        return {
            content: data.choices[0]?.text || '',
            model: data.model || model,
        };
    }

    /**
     * Call OpenAI API
     */
    private async callOpenAi(
        apiUrl: string,
        model: string,
        prompt: string,
        apiKey: string,
        signal: AbortSignal,
    ): Promise<{ content: string; model: string }> {
        const response = await fetch(`${apiUrl}/v1/chat/completions`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`,
            },
            body: JSON.stringify({
                model,
                messages: [
                    { role: 'system', content: 'ë‹¹ì‹ ì€ ë³´ì•ˆ ì·¨ì•½ì  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.' },
                    { role: 'user', content: prompt },
                ],
                temperature: 0.7,
            }),
            signal,
        });

        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
        }

        const data = await response.json() as { choices: Array<{ message: { content: string } }>; model: string };
        return {
            content: data.choices[0]?.message?.content || '',
            model: data.model || model,
        };
    }

    /**
     * Estimate tokens for given action and context
     */
    estimateTokens(action: AiActionType, context: Record<string, unknown>): TokenEstimate {
        const metadata = AI_ACTION_METADATA[action];
        const contextStr = JSON.stringify(context);

        // Rough estimation: ~4 characters per token
        const contextTokens = Math.ceil(contextStr.length / 4);
        const promptTokens = 500; // Base prompt tokens

        return {
            inputTokens: Math.min(contextTokens + promptTokens, metadata?.maxContextTokens || 2000),
            outputTokens: metadata?.expectedOutputTokens || 500,
        };
    }

    /**
     * Mask PII in text
     */
    private maskPii(text: string): string {
        // Mask email addresses
        let masked = text.replace(/[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/g, '[EMAIL]');
        // Mask phone numbers (Korean format)
        masked = masked.replace(/\d{2,3}-\d{3,4}-\d{4}/g, '[PHONE]');
        // Mask IP addresses
        masked = masked.replace(/\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b/g, '[IP]');
        return masked;
    }

    /**
     * Generate summary from content (first meaningful sentence)
     */
    private generateSummaryFromContent(content: string): string {
        const lines = content.split('\n').filter(line => line.trim().length > 0);
        if (lines.length === 0) return '';

        // Find first non-header line
        for (const line of lines) {
            if (!line.startsWith('#') && !line.startsWith('-') && line.length > 20) {
                return line.slice(0, 150) + (line.length > 150 ? '...' : '');
            }
        }
        return lines[0].slice(0, 150);
    }

    /**
     * Generate mock response for development
     * TODO: Replace with actual LLM integration
     */
    private async generateMockResponse(
        action: AiActionType,
        context: Record<string, unknown>,
    ): Promise<string> {
        // Simulate processing delay
        await new Promise(resolve => setTimeout(resolve, 1000));

        switch (action) {
            case 'dashboard.summary':
                return this.generateDashboardSummaryMock(context);
            case 'dashboard.riskAnalysis':
                return this.generateRiskAnalysisMock(context);
            case 'project.analysis':
                return this.generateProjectAnalysisMock(context);
            case 'vuln.actionGuide':
                return this.generateVulnActionGuideMock(context);
            case 'vuln.priorityReorder':
                return this.generatePriorityReorderMock(context);
            case 'policy.interpretation':
                return this.generatePolicyInterpretationMock(context);
            case 'notification.summary':
                return this.generateNotificationSummaryMock(context);
            case 'guide.trivyCommand':
                return this.generateTrivyCommandMock(context);
            default:
                return this.generateGenericMock(action, context);
        }
    }

    private generateDashboardSummaryMock(context: Record<string, unknown>): string {
        const overview = context.overview as Record<string, unknown> | undefined;
        return `## ì·¨ì•½ì  í˜„í™© ìš”ì•½

í˜„ì¬ ì‹œìŠ¤í…œì˜ ë³´ì•ˆ ìƒíƒœë¥¼ ë¶„ì„í•œ ê²°ê³¼, ì „ë°˜ì ì¸ ë³´ì•ˆ ìˆ˜ì¤€ì€ **ì£¼ì˜ í•„ìš”** ë‹¨ê³„ì…ë‹ˆë‹¤.

### ì£¼ìš” ë°œê²¬ ì‚¬í•­
- Critical ë“±ê¸‰ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì–´ ì¦‰ê°ì ì¸ ì¡°ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤
- ìµœê·¼ 7ì¼ê°„ ì·¨ì•½ì  ì¶”ì´ê°€ ì¦ê°€í•˜ëŠ” ì–‘ìƒì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤
- íŠ¹ì • í”„ë¡œì íŠ¸ì— ì·¨ì•½ì ì´ ì§‘ì¤‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤

### ê¶Œì¥ ì¡°ì¹˜
1. Critical ì·¨ì•½ì ì— ëŒ€í•œ ê¸´ê¸‰ íŒ¨ì¹˜ ì ìš©
2. High ì·¨ì•½ì  í•´ê²°ì„ ìœ„í•œ 7ì¼ ë‚´ ê³„íš ìˆ˜ë¦½
3. ì·¨ì•½ì  ë°œìƒ íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì¡°ì¹˜ ê°•í™”

*ì´ ë¶„ì„ì€ AIê°€ ìë™ ìƒì„±í•œ ê²ƒìœ¼ë¡œ, ìƒì„¸ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.*`;
    }

    private generateRiskAnalysisMock(context: Record<string, unknown>): string {
        return `## ì¡°ì§ ìœ„í—˜ ë¶„ì„ ê²°ê³¼

### Top 5 ìœ„í—˜ ìš”ì¸

1. **ì˜¤ë˜ëœ ì˜ì¡´ì„± íŒ¨í‚¤ì§€ (ìœ„í—˜ë„: ë†’ìŒ)**
   - ë‹¤ìˆ˜ì˜ í”„ë¡œì íŠ¸ì—ì„œ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì€ npm íŒ¨í‚¤ì§€ ì‚¬ìš©
   - ì•Œë ¤ì§„ ì·¨ì•½ì ì„ í¬í•¨í•œ ë²„ì „ ì‚¬ìš© ì¤‘

2. **Critical CVE ë¯¸ì¡°ì¹˜ (ìœ„í—˜ë„: ë†’ìŒ)**
   - 30ì¼ ì´ìƒ ë¯¸í•´ê²°ëœ Critical ì·¨ì•½ì  ì¡´ì¬
   - ê³µê°œ ìµìŠ¤í”Œë¡œì‡ ì¡´ì¬ ê°€ëŠ¥ì„±

3. **ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì·¨ì•½ì  (ìœ„í—˜ë„: ì¤‘ê°„)**
   - ë² ì´ìŠ¤ ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸ í•„ìš”
   - alpine ê¸°ë°˜ ì´ë¯¸ì§€ë¡œ ì „í™˜ ê¶Œì¥

4. **ì¼ê´€ì„± ì—†ëŠ” ì •ì±… ì ìš© (ìœ„í—˜ë„: ì¤‘ê°„)**
   - í”„ë¡œì íŠ¸ë³„ ë³´ì•ˆ ì •ì±… í¸ì°¨ ì¡´ì¬
   - í†µí•© ë³´ì•ˆ ê¸°ì¤€ í•„ìš”

5. **ìŠ¤ìº” ì£¼ê¸° ë¶ˆê·œì¹™ (ìœ„í—˜ë„: ë‚®ìŒ)**
   - ì¼ë¶€ í”„ë¡œì íŠ¸ ìŠ¤ìº” ë¯¸ì‹¤í–‰
   - ìë™í™”ëœ ìŠ¤ìº” íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê¶Œì¥`;
    }

    private generateProjectAnalysisMock(context: Record<string, unknown>): string {
        return `## í”„ë¡œì íŠ¸ ë³´ì•ˆ ë¶„ì„

### ë¶„ì„ ê°œìš”
í”„ë¡œì íŠ¸ì˜ ë³´ì•ˆ ìƒíƒœë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.

### ì£¼ìš” ë¦¬ìŠ¤í¬ ì›ì¸
1. **ì˜¤ë˜ëœ Node.js íŒ¨í‚¤ì§€**: lodash, moment ë“± deprecated íŒ¨í‚¤ì§€ ì‚¬ìš©
2. **ì•Œë ¤ì§„ CVE**: 3ê°œì˜ Critical CVEê°€ ë¯¸í•´ê²° ìƒíƒœ
3. **ì»¨í…Œì´ë„ˆ êµ¬ì„±**: root ì‚¬ìš©ìë¡œ ì‹¤í–‰ë˜ëŠ” ì»¨í…Œì´ë„ˆ ë°œê²¬

### ê¶Œì¥ ì¡°ì¹˜
- íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ ë˜ëŠ” ëŒ€ì²´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
- ì»¨í…Œì´ë„ˆ ë³´ì•ˆ ëª¨ë²” ì‚¬ë¡€ ì ìš©
- ì •ê¸°ì ì¸ ë³´ì•ˆ ìŠ¤ìº” ìë™í™”`;
    }

    private generateVulnActionGuideMock(context: Record<string, unknown>): string {
        return `## ì·¨ì•½ì  ì¡°ì¹˜ ê°€ì´ë“œ

### ì·¨ì•½ì  ê°œìš”
í•´ë‹¹ ì·¨ì•½ì ì€ ì›ê²© ì½”ë“œ ì‹¤í–‰(RCE)ì„ í—ˆìš©í•  ìˆ˜ ìˆëŠ” ì‹¬ê°í•œ ë³´ì•ˆ ë¬¸ì œì…ë‹ˆë‹¤.

### ì¡°ì¹˜ ë‹¨ê³„

#### 1ë‹¨ê³„: ì˜í–¥ ë²”ìœ„ íŒŒì•…
\`\`\`bash
trivy image --severity CRITICAL your-image:tag
\`\`\`

#### 2ë‹¨ê³„: íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸
\`\`\`bash
npm update affected-package
# ë˜ëŠ”
yarn upgrade affected-package
\`\`\`

#### 3ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- í†µí•© í…ŒìŠ¤íŠ¸ë¡œ ê¸°ëŠ¥ í™•ì¸
- ì¬ìŠ¤ìº”ìœ¼ë¡œ ì·¨ì•½ì  í•´ê²° í™•ì¸

### ì„ì‹œ ì™„í™” ì¡°ì¹˜
íŒ¨ì¹˜ê°€ ì¦‰ì‹œ ì–´ë ¤ìš´ ê²½ìš°:
- ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼ ì œí•œ
- WAF ê·œì¹™ ì¶”ê°€
- ëª¨ë‹ˆí„°ë§ ê°•í™”

### ì°¸ê³  ìë£Œ
- [NVD ìƒì„¸ ì •ë³´](https://nvd.nist.gov)
- [íŒ¨í‚¤ì§€ ë³´ì•ˆ ê¶Œê³ ](https://github.com/advisories)`;
    }

    private generatePriorityReorderMock(context: Record<string, unknown>): string {
        return `## AI ê¸°ë°˜ ì·¨ì•½ì  ìš°ì„ ìˆœìœ„

### ì¬ì •ë ¬ ê¸°ì¤€
- EPSS ì ìˆ˜ (ìµìŠ¤í”Œë¡œì‡ ì˜ˆì¸¡)
- ê³µê°œ ìµìŠ¤í”Œë¡œì‡ ì¡´ì¬ ì—¬ë¶€
- ìì‚° ë…¸ì¶œ ì •ë„
- ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ë„

### ìš°ì„ ìˆœìœ„ ëª©ë¡

| ìˆœìœ„ | CVE ID | ê¸°ì¡´ ìˆœìœ„ | EPSS | ì¬ì •ë ¬ ì‚¬ìœ  |
|------|--------|-----------|------|-------------|
| 1 | CVE-2024-0001 | 3 | 0.92 | ê³µê°œ ìµìŠ¤í”Œë¡œì‡ ì¡´ì¬ |
| 2 | CVE-2024-0002 | 1 | 0.78 | ì¸í„°ë„· ë…¸ì¶œ ì„œë¹„ìŠ¤ |
| 3 | CVE-2024-0003 | 2 | 0.45 | ë‚´ë¶€ë§ í•œì • |

*EPSS ë°ì´í„°ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.*`;
    }

    private generatePolicyInterpretationMock(context: Record<string, unknown>): string {
        return `## ì •ì±… ì°¨ë‹¨ ì‚¬ìœ  ì„¤ëª…

### ì ìš©ëœ ì •ì±…
**"Critical ì·¨ì•½ì  ì°¨ë‹¨ ì •ì±…"**

### ì°¨ë‹¨ ì´ìœ 
ì´ ë°°í¬ê°€ ì°¨ë‹¨ëœ ì´ìœ ëŠ” ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì—ì„œ **Critical ë“±ê¸‰ì˜ ì·¨ì•½ì **ì´ ë°œê²¬ë˜ì—ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

### ìƒì„¸ ì„¤ëª…
1. ìŠ¤ìº” ê²°ê³¼ 2ê°œì˜ Critical ì·¨ì•½ì  ë°œê²¬
2. ì¡°ì§ ì •ì±…ì— ë”°ë¼ Critical ì·¨ì•½ì ì´ ìˆëŠ” ì´ë¯¸ì§€ëŠ” í”„ë¡œë•ì…˜ ë°°í¬ ë¶ˆê°€
3. í•´ë‹¹ ì·¨ì•½ì ì€ ì›ê²© ì½”ë“œ ì‹¤í–‰ ìœ„í—˜ì´ ìˆìŒ

### í•´ê²° ë°©ë²•
1. ë°œê²¬ëœ ì·¨ì•½ì  íŒ¨ì¹˜ í›„ ì¬ìŠ¤ìº”
2. ë˜ëŠ” ì˜ˆì™¸ ìŠ¹ì¸ ìš”ì²­ (ë¹„ì¦ˆë‹ˆìŠ¤ ì‚¬ìœ  í•„ìš”)

*ì •ì±… ë¬¸ì˜: security@company.com*`;
    }

    private generateNotificationSummaryMock(context: Record<string, unknown>): string {
        const notifications = context.notifications as unknown[] | undefined;
        const count = notifications?.length || 0;

        return `## ì•Œë¦¼ ìš”ì•½ (${count}ê±´)

### ê¸´ê¸‰ ì¡°ì¹˜ í•„ìš”
- ğŸ”´ Critical ì·¨ì•½ì  2ê±´ ì‹ ê·œ ë°œê²¬

### ê²€í†  í•„ìš”
- ğŸŸ¡ ì •ì±… ìœ„ë°˜ 3ê±´
- ğŸŸ¡ ìŠ¤ìº” ì™„ë£Œ 5ê±´

### ì •ë³´ì„±
- ğŸ”µ í”„ë¡œì íŠ¸ ì—…ë°ì´íŠ¸ 2ê±´

### ê¶Œì¥ ì¡°ì¹˜
1. Critical ì·¨ì•½ì  ë¨¼ì € ê²€í† 
2. ì •ì±… ìœ„ë°˜ í•­ëª© í™•ì¸ í›„ ì¡°ì¹˜
3. ë‚˜ë¨¸ì§€ëŠ” ì¼ì¼ ë¦¬ë·° ì‹œ ì²˜ë¦¬`;
    }

    private generateTrivyCommandMock(context: Record<string, unknown>): string {
        return `## Trivy ëª…ë ¹ì–´

### ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ìŠ¤ìº”
\`\`\`bash
trivy image --format json --output result.json your-image:tag
\`\`\`

### íŒŒì¼ì‹œìŠ¤í…œ ìŠ¤ìº”
\`\`\`bash
trivy fs --format sarif --output result.sarif ./
\`\`\`

### CI/CD í†µí•© (GitHub Actions)
\`\`\`yaml
- name: Run Trivy vulnerability scanner
  uses: aquasecurity/trivy-action@master
  with:
    image-ref: '\${{ env.IMAGE }}'
    format: 'json'
    output: 'trivy-results.json'
    severity: 'CRITICAL,HIGH'
\`\`\`

### ì˜µì…˜ ì„¤ëª…
- \`--format json\`: JASCA í˜¸í™˜ í˜•ì‹
- \`--severity CRITICAL,HIGH\`: ì‹¬ê°ë„ í•„í„°
- \`--ignore-unfixed\`: íŒ¨ì¹˜ ì—†ëŠ” ì·¨ì•½ì  ì œì™¸`;
    }

    private generateGenericMock(action: AiActionType, context: Record<string, unknown>): string {
        const metadata = AI_ACTION_METADATA[action];
        return `## ${metadata?.label || 'AI ë¶„ì„ ê²°ê³¼'}

AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

### ë¶„ì„ ë‚´ìš©
ìš”ì²­í•˜ì‹  "${action}" ì‘ì—…ì— ëŒ€í•œ ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.

### ì»¨í…ìŠ¤íŠ¸ ìš”ì•½
ì…ë ¥ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.

*ìƒì„¸ ë¶„ì„ ê¸°ëŠ¥ì€ AI ëª¨ë¸ ì—°ë™ í›„ ì œê³µë©ë‹ˆë‹¤.*`;
    }


    /**
     * Generate AI-powered risk summary for a project
     * Note: In production, this would call an LLM API
     */
    async generateRiskSummary(projectId: string): Promise<RiskSummary> {
        const project = await this.prisma.project.findUnique({
            where: { id: projectId },
            include: {
                scanResults: {
                    orderBy: { createdAt: 'desc' },
                    take: 1,
                    include: {
                        vulnerabilities: {
                            include: { vulnerability: true },
                        },
                    },
                },
            },
        });

        if (!project || project.scanResults.length === 0) {
            return {
                projectId,
                projectName: project?.name || 'Unknown',
                summary: 'No scan data available for risk assessment.',
                riskLevel: 'LOW',
                keyFindings: [],
                recommendations: [],
                generatedAt: new Date(),
            };
        }

        const latestScan = project.scanResults[0];
        const vulns = latestScan.vulnerabilities;

        let criticalCount = 0;
        let highCount = 0;
        let mediumCount = 0;

        for (const sv of vulns) {
            const sev = sv.vulnerability.severity;
            if (sev === 'CRITICAL') criticalCount++;
            else if (sev === 'HIGH') highCount++;
            else if (sev === 'MEDIUM') mediumCount++;
        }

        // Determine risk level
        let riskLevel: 'CRITICAL' | 'HIGH' | 'MEDIUM' | 'LOW' = 'LOW';
        if (criticalCount > 0) riskLevel = 'CRITICAL';
        else if (highCount > 3) riskLevel = 'HIGH';
        else if (highCount > 0 || mediumCount > 5) riskLevel = 'MEDIUM';

        // Generate summary (in production, this would be LLM-generated)
        const summary = this.generateSummaryText(project.name, criticalCount, highCount, mediumCount, vulns.length);

        const keyFindings = this.extractKeyFindings(vulns);
        const recommendations = this.generateRecommendations(criticalCount, highCount, vulns);

        return {
            projectId,
            projectName: project.name,
            summary,
            riskLevel,
            keyFindings,
            recommendations,
            generatedAt: new Date(),
        };
    }

    /**
     * Generate remediation guide for a CVE
     * Note: In production, this would call an LLM API
     */
    async generateRemediationGuide(cveId: string): Promise<RemediationGuide | null> {
        const vulnerability = await this.prisma.vulnerability.findUnique({
            where: { cveId },
        });

        if (!vulnerability) return null;

        // In production, this would use LLM to generate context-aware steps
        const steps = this.generateRemediationSteps(vulnerability);
        const estimatedEffort = this.estimateEffort(vulnerability.severity);

        return {
            cveId,
            title: vulnerability.title || cveId,
            severity: vulnerability.severity,
            description: vulnerability.description || 'No description available.',
            steps,
            references: [
                `https://nvd.nist.gov/vuln/detail/${cveId}`,
                ...(vulnerability.references || []).slice(0, 3),
            ],
            estimatedEffort,
            generatedAt: new Date(),
        };
    }

    /**
     * Batch generate remediation guides for a scan
     */
    async batchGenerateGuides(scanResultId: string): Promise<RemediationGuide[]> {
        const scan = await this.prisma.scanResult.findUnique({
            where: { id: scanResultId },
            include: {
                vulnerabilities: {
                    include: { vulnerability: true },
                    where: {
                        vulnerability: {
                            severity: { in: ['CRITICAL', 'HIGH'] },
                        },
                    },
                },
            },
        });

        if (!scan) return [];

        const guides: RemediationGuide[] = [];
        const seen = new Set<string>();

        for (const sv of scan.vulnerabilities) {
            if (seen.has(sv.vulnerability.cveId)) continue;
            seen.add(sv.vulnerability.cveId);

            const guide = await this.generateRemediationGuide(sv.vulnerability.cveId);
            if (guide) guides.push(guide);
        }

        return guides;
    }

    // Helper methods

    private generateSummaryText(
        projectName: string,
        critical: number,
        high: number,
        medium: number,
        total: number,
    ): string {
        if (critical > 0) {
            return `${projectName} has ${critical} critical vulnerabilities that require immediate attention. ` +
                `Total vulnerabilities: ${total} (${critical} critical, ${high} high, ${medium} medium).`;
        }
        if (high > 0) {
            return `${projectName} has ${high} high-severity vulnerabilities. ` +
                `Total vulnerabilities: ${total}. Consider prioritizing remediation.`;
        }
        return `${projectName} has ${total} vulnerabilities. No critical issues detected.`;
    }

    private extractKeyFindings(vulns: { vulnerability: { cveId: string; severity: string; title: string | null } }[]): string[] {
        const findings: string[] = [];
        const criticals = vulns.filter(v => v.vulnerability.severity === 'CRITICAL');

        for (const cv of criticals.slice(0, 3)) {
            findings.push(`${cv.vulnerability.cveId}: ${cv.vulnerability.title || 'Critical vulnerability'}`);
        }

        if (criticals.length > 3) {
            findings.push(`...and ${criticals.length - 3} more critical vulnerabilities`);
        }

        return findings;
    }

    private generateRecommendations(
        critical: number,
        high: number,
        vulns: { vulnerability: { severity: string; cweIds: string[] | null } }[],
    ): string[] {
        const recs: string[] = [];

        if (critical > 0) {
            recs.push('Immediately patch or mitigate critical vulnerabilities');
            recs.push('Review network exposure to affected components');
        }
        if (high > 0) {
            recs.push('Schedule high-severity vulnerability remediation within 7 days');
        }

        // Check for common patterns
        const cweIds = vulns.flatMap(v => v.vulnerability.cweIds || []);
        if (cweIds.includes('CWE-79')) {
            recs.push('Review input sanitization practices to prevent XSS');
        }
        if (cweIds.includes('CWE-89')) {
            recs.push('Audit database queries for SQL injection vulnerabilities');
        }

        return recs.slice(0, 5);
    }

    private generateRemediationSteps(vuln: { severity: string; cweIds: string[] | null }): string[] {
        const steps: string[] = [
            'Identify all instances of this vulnerability in your codebase',
            'Review the affected component and its dependencies',
        ];

        const cweIds = vuln.cweIds || [];

        if (cweIds.includes('CWE-79')) {
            steps.push('Implement proper output encoding for user-supplied data');
            steps.push('Use Content Security Policy headers');
        } else if (cweIds.includes('CWE-89')) {
            steps.push('Use parameterized queries or prepared statements');
            steps.push('Validate and sanitize all user inputs');
        } else if (cweIds.some(c => c.includes('119') || c.includes('120'))) {
            steps.push('Update to the latest patched version of the affected library');
            steps.push('Review buffer handling code for bounds checking');
        } else {
            steps.push('Update the affected package to the latest patched version');
            steps.push('Review vendor advisories for specific mitigation steps');
        }

        steps.push('Test the fix in a staging environment');
        steps.push('Deploy the fix and verify remediation with a rescan');

        return steps;
    }

    private estimateEffort(severity: string): 'LOW' | 'MEDIUM' | 'HIGH' {
        switch (severity) {
            case 'CRITICAL':
                return 'HIGH';
            case 'HIGH':
                return 'MEDIUM';
            default:
                return 'LOW';
        }
    }
}
